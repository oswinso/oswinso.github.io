---
---

@article{so2022multimodal,
    abbr={RSS 2022},
    author    = {Oswin So and
               Kyle Stachowicz and
               Evangelos A. Theodorou},
    title     = {Multimodal Maximum Entropy Dynamic Games},
    journal   = {RSS 2022 (in submission)},
    year      = {2022},
    abstract = {Environments with multi-agent interactions often result a rich set of modalities of behavior between agents due to the inherent suboptimality of decision making processes when agents settle for satisfactory decisions. However, existing algorithms for solving these dynamic games are strictly unimodal and fail to capture the intricate multimodal behaviors of the agents. In this paper, we propose MMELQGames (Multimodal Maximum-Entropy Linear Quadratic Games), a novel constrained multimodal maximum entropy formulation of the Differential Dynamic Programming algorithm for solving generalized Nash equilibria. By formulating the problem as a certain dynamic game with incomplete and asymmetric information where agents are uncertain about the cost and dynamics of the game itself, the proposed method is able to reason about multiple local generalized Nash equilibria, enforce constraints with the Augmented Lagrangian framework and also perform Bayesian inference on the latent mode from past observations. We assess the efficacy of the proposed algorithm on two illustrative examples: multi-agent collision avoidance and autonomous racing. In particular, we show that only MMELQGames is able to effectively block a rear vehicle when given a speed disadvantage and the rear vehicle can overtake from multiple positions.},
    pdf = {So_2022_Multimodal_Maximum_Entropy_Dynamic_Games.pdf},
    video = {https://youtu.be/7molN_Q38dk}
}

@article{pereira2022decentralized,
    abbr={RSS 2022},
    author    = {Marcus A. Pereira and
                Augustinos D. Saravanos and
                Oswin So and
               Evangelos A. Theodorou},
    title     = {Decentralized Safe Multi-agent Stochastic Optimal Control using Deep FBSDEs and ADMM},
    journal   = {RSS 2022 (in submission)},
    year      = {2022},
    abstract = {In this work, we propose a novel safe and scalable decentralized solution for multi-agent control in the presence of stochastic disturbances. Safety is mathematically encoded using stochastic control barrier functions and safe controls are computed by solving quadratic programs. Decentralization is achieved by augmenting to each agentâ€™s optimization variables, copy variables, for its neighboring agents. This allows us to decouple the centralized multi-agent optimization problem. How- ever, to ensure safety, neighboring agents must agree on what is safe for both of us and this creates a need for consensus. To enable safe consensus solutions, we incorporate an ADMM- based approach. Specifically, we propose a Merged CADMM- OSQP implicit neural network layer, that solves a mini-batch of both, local quadratic programs as well as the overall con- sensus problem, as a single optimization problem. This layer is embedded within a Deep FBSDEs network architecture at every time step, to facilitate end-to-end differentiable, safe and decentralized stochastic optimal control. The efficacy of the proposed approach is demonstrated on several challenging multi- robot tasks in simulation. By imposing requirements on safety specified by collision avoidance constraints, the safe operation of all agents is ensured during the entire training process. We also demonstrate superior scalability in terms of computational and memory savings as compared to a centralized approach.},
    pdf = {Pereira_et_al_Decentralized_Safe_Multi-agent_Stochastic_Optimal_Control_using_Deep_FBSDEs.pdf},
    video = {https://youtu.be/xewGeuDcDho}
}

@article{so2021maximum,
    abbr={ICRA 2022},
    author    = {Oswin So and
                 Ziyi Wang and
                 Evangelos A. Theodorou},
    title     = {Maximum Entropy Differential Dynamic Programming},
    journal   = {ICRA 2022},
    volume    = {abs/2110.06451},
    year      = {2021},
    abstract={In this paper, we present a novel maximum entropy formulation of the Differential Dynamic Programming algorithm and derive two variants using unimodal and multimodal value functions parameterizations. By combining the maximum entropy Bellman equations with a particular approximation of the cost function, we are able to obtain a new formulation of Differential Dynamic Programming which is able to escape from local minima via exploration with a multimodal policy. To demonstrate the efficacy of the proposed algorithm, we provide experimental results using four systems on tasks that are represented by cost functions with multiple local minima and compare them against vanilla Differential Dynamic Programming. Furthermore, we discuss connections with previous work on the linearly solvable stochastic control framework and its extensions in relation to compositionality.},
    url       = {https://arxiv.org/abs/2110.06451},
    eprinttype = {arXiv},
    eprint    = {2110.06451},
    arxiv={2110.06451},
    video = {https://youtu.be/NHr9Kj_jnAI}
}



@inproceedings{wang2021variational,
  abbr={RSS 2021},
  title={Variational Inference MPC using Tsallis Divergence},
  author={Wang*, Ziyi and So*, Oswin and Gibson, Jason and Vlahov, Bogdan and Gandhi, Manan S and Liu, Guan-Horng and Theodorou, Evangelos A},
  booktitle={Robotics: Science and Systems (*Equal Contribution)},
  year={2021},
  abstract={In this paper, we provide a generalized framework for Variational Inference-Stochastic Optimal Control by using thenon-extensive Tsallis divergence. By incorporating the deformed exponential function into the optimality likelihood function, a novel Tsallis Variational Inference-Model Predictive Control algorithm is derived, which includes prior works such as Variational Inference-Model Predictive Control, Model Predictive PathIntegral Control, Cross Entropy Method, and Stein VariationalInference Model Predictive Control as special cases. The proposed algorithm allows for effective control of the cost/reward transform and is characterized by superior performance in terms of mean and variance reduction of the associated cost. The aforementioned features are supported by a theoretical and numerical analysis on the level of risk sensitivity of the proposed algorithm as well as simulation experiments on 5 different robotic systems with 3 different policy parameterizations.},
  arxiv={2104.00241},
}


@article{evans2021spatio,
  abbr={arxiv},
  title={Spatio-Temporal Differential Dynamic Programming for Control of Fields},
  author={Evans, Ethan N and So, Oswin and Kendall, Andrew P and Liu, Guan-Horng and Theodorou, Evangelos A},
  journal={arXiv preprint (in submission)},
  year={2021},
  abstract={We consider the optimal control problem of a general nonlinear spatio-temporal system described by Partial Differential Equations (PDEs). Theory and algorithms for control of spatio-temporal systems are of rising interest among the automatic control community and exhibit numerous challenging characteristic from a control standpoint. Recent methods focus on finite-dimensional optimization techniques of a discretized finite dimensional ODE approximation of the infinite dimensional PDE system. In this paper, we derive a differential dynamic programming (DDP) framework for distributed and boundary control of spatio-temporal systems in infinite dimensions that is shown to generalize both the spatio-temporal LQR solution, and modern finite dimensional DDP frameworks. We analyze the convergence behavior and provide a proof of global convergence for the resulting system of continuous-time forward-backward equations. We explore and develop numerical approaches to handle sensitivities that arise during implementation, and apply the resulting STDDP algorithm to a linear and nonlinear spatio-temporal PDE system. Our framework is derived in infinite dimensional Hilbert spaces, and represents a discretization-agnostic framework for control of nonlinear spatio-temporal PDE systems.},
  arxiv={2104.04044},
}

@inproceedings{wang2021adaptive,
  abbr={L4DC 2021},
  author    = {Ziyi Wang and
               Oswin So and
               Keuntaek Lee and
               Evangelos A. Theodorou},
  editor    = {Ali Jadbabaie and
               John Lygeros and
               George J. Pappas and
               Pablo A. Parrilo and
               Benjamin Recht and
               Claire J. Tomlin and
               Melanie N. Zeilinger},
  title     = {Adaptive Risk Sensitive Model Predictive Control with Stochastic Search},
  booktitle = { Learning for Dynamics & Control Conference},
  series    = {Proceedings of Machine Learning Research},
  volume    = {144},
  pages     = {510--522},
  publisher = {{PMLR}},
  year      = {2021},
  abstract={We present a general framework for optimizing the Conditional Value-at-Risk for dynamical systems using stochastic search. The framework is capable of handling the uncertainty from the initial condition, stochastic dynamics, and uncertain parameters in the model. The algorithm is compared against a risk-sensitive distributional reinforcement learning framework and demonstrates outperformance on a pendulum and cartpole with stochastic dynamics. We also showcase the applicability of the framework to robotics as an adaptive risk-sensitive controller by optimizing with respect to the fully nonlinear belief provided by a particle filter on a pendulum, cartpole, and quadcopter in simulation.},
  url       = {http://proceedings.mlr.press/v144/wang21b.html},
  arxiv={2009.01090},
}
